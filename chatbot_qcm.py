# -*- coding: utf-8 -*-

import json
import openai
import streamlit
import sys



key = st.secrets["OPENAI_API_KEY"]

try:
    key.encode("ascii")
except UnicodeEncodeError:
    st.error("‚ùå La cl√© API contient un caract√®re accentu√© ou invisible. Veuillez en recr√©er une.")
    sys.exit()

# Initialisation du client OpenAI avec la cl√© depuis les secrets
client = openai.OpenAI(api_key=st.secrets["OPENAI_API_KEY"])

# Liste des chapitres du programme sp√©cifique de Premi√®re
chapitres = [
    "Fonctions",
    "Calcul litt√©ral",
    "Statistiques",
    "Probabilit√©s",
    "G√©om√©trie",
    "Nombres et calculs",
    "Grandeurs et mesures"
]

st.set_page_config(page_title="Chatbot QCM Maths", page_icon="üßÆ")
st.title("ü§ñ Chatbot QCM ‚Äì Maths Premi√®re (enseignement sp√©cifique)")
st.markdown("Choisis un chapitre pour g√©n√©rer une question de QCM adapt√©e au programme.")

# Choix de chapitre
chapitre_choisi = st.selectbox("üìò Chapitre :", chapitres)

if st.button("üé≤ G√©n√©rer une question"):
    with st.spinner("GPT pr√©pare une question adapt√©e..."):
        chapitre_choisi = chapitre_choisi or "Fonctions"

        prompt_data = {
            "instructions": f"""Tu es un professeur de math√©matiques. G√©n√®re une question de type QCM pour le niveau Premi√®re - Math√©matiques sp√©cifiques.

- Le th√®me est : {theme}
- R√©dige une question claire.
- Donne 4 propositions (A, B, C, D), dont une seule est correcte.
- M√©lange al√©atoirement l'ordre des propositions.
- Indique la lettre de la bonne r√©ponse.
- Donne une explication claire et p√©dagogique pour justifier la bonne r√©ponse, m√™me si l'√©l√®ve s‚Äôest tromp√©.

R√©ponds dans ce format JSON structur√© :""",
            "json_format": {
                "question": "...",
                "options": {
                    "A": "...",
                    "B": "...",
                    "C": "...",
                    "D": "..."
                },
                "correct_answer": "B",
                "explanation": "..."
            }
        }

        prompt = prompt_data["instructions"] + "\n\n" + json.dumps(prompt_data["json_format"], indent=2)

        try:
            response = client.chat.completions.create(
                model="gpt-3.5-turbo",
                messages=[{"role": "user", "content": prompt}],
                temperature=0.7
            )

            content = response.choices[0].message.content.strip()
            qcm = json.loads(content)

            # Affichage dans l'app
            st.markdown(f"### ‚ùì Question :\n{qcm['question']}")
            for key, value in qcm["options"].items():
                st.markdown(f"**{key}** : {value}")

            if "correct_answer" in qcm:
                st.success(f"‚úÖ Bonne r√©ponse : {qcm['correct_answer']}")
            if "explanation" in qcm:
                st.info(f"‚ÑπÔ∏è Explication : {qcm['explanation']}")

        except Exception as e:
            st.error(f"‚ùå Erreur lors de l‚Äôappel √† l‚ÄôAPI : {str(e)}")
