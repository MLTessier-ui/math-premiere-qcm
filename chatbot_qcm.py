# -*- coding: utf-8 -*-

import json
import openai
import streamlit as st
import sys

# Configuration de la page Streamlit
st.set_page_config(page_title="Chatbot QCM Maths", page_icon="üßÆ")
st.title("ü§ñ Chatbot QCM ‚Äì Maths Premi√®re (enseignement sp√©cifique)")
st.markdown("Choisis un chapitre pour g√©n√©rer une question de QCM adapt√©e au programme.")

# Liste de chapitres disponibles
chapitres = [
    "Fonctions",
    "D√©rivation",
    "Statistiques",
    "Suites",
    "Trigonom√©trie",
    "Probabilit√©s",
    "G√©om√©trie",
    "Nombres et calculs",
    "Grandeurs et mesures"
]

# Choix du chapitre
chapitre_choisi = st.selectbox("üìò Chapitre :", chapitres)

# R√©cup√©ration de la cl√© API
try:
    key = st.secrets["OPENAI_API_KEY"]
    key.encode("ascii")
except (KeyError, UnicodeEncodeError):
    st.error("‚ùå Cl√© API invalide ou manquante.")
    sys.exit()

# Initialisation du client OpenAI
client = openai.OpenAI(api_key=key)

# Bouton de g√©n√©ration
if st.button("üé≤ G√©n√©rer une question"):
    with st.spinner("GPT pr√©pare une question adapt√©e..."):
        # Construction du prompt
        prompt_data = {
            "instructions": f"""Tu es un professeur de math√©matiques. G√©n√©re une question de type QCM pour le niveau Premi√®re - Math√©matiques.

- Le chapitre est : {chapitre_choisi}
- R√©dige une question claire.
- Donne 4 propositions (A, B, C, D), dont une seule est correcte.
- M√©lange al√©atoirement l'ordre des propositions.
- Indique la lettre de la bonne r√©ponse.
- Donne une explication claire et p√©dagogique.

R√©ponds dans ce format JSON structur√© :""",
            "json_format": {
                "question": "...",
                "options": {
                    "A": "...",
                    "B": "...",
                    "C": "...",
                    "D": "..."
                },
                "correct_answer": "B",
                "explanation": "..."
            }
        }

        prompt = prompt_data["instructions"] + "\n\n" + json.dumps(prompt_data["json_format"], indent=2)

        try:
            response = client.chat.completions.create(
                model="gpt-3.5-turbo",
                messages=[{"role": "user", "content": prompt}],
                temperature=0.7
            )

            data = json.loads(response.choices[0].message.content)

            st.markdown(f"**‚ùì Question :** {data['question']}")

            # Affichage des options
            user_answer = st.radio(
                "Choisis ta r√©ponse :",
                list(data["options"].keys()),
                format_func=lambda x: f"{x} : {data['options'][x]}",
                key="qcm_radio"
            )

            # Bouton de validation
            if st.button("‚úÖ Valider ma r√©ponse"):
                if user_answer == data["correct_answer"]:
                    st.success("‚úÖ Bonne r√©ponse !")
                else:
                    st.error(
                        f"‚ùå Mauvaise r√©ponse. La bonne r√©ponse √©tait {data['correct_answer']} : {data['options'][data['correct_answer']]}"
                    )
                st.markdown(f"**Explication** : {data['explanation']}")

        except Exception as e:
            st.error(f"‚ùå Erreur lors de la g√©n√©ration : {e}")
