# -*- coding: utf-8 -*-

import json
import openai
import streamlit as st
import sys

# Configuration de la page
st.set_page_config(page_title="Chatbot QCM Maths", page_icon="üßÆ")
st.title("ü§ñ Chatbot QCM ‚Äì Maths Premi√®re (enseignement sp√©cifique)")
st.markdown("Choisis un chapitre pour g√©n√©rer une question de QCM adapt√©e au programme.")

# Liste des chapitres du programme sp√©cifique de Premi√®re
chapitres = [
    "Fonctions",
    "Calcul litt√©ral",
    "Statistiques",
    "Probabilit√©s",
    "G√©om√©trie",
    "Nombres et calculs",
    "Grandeurs et mesures"
]

# Choix de chapitre
chapitre_choisi = st.selectbox("üìò Chapitre :", chapitres)

# Cl√© API
try:
    key = st.secrets["OPENAI_API_KEY"]
    key.encode("ascii")
except UnicodeEncodeError:
    st.error("‚ùå La cl√© API contient un caract√®re accentu√© ou invisible. Veuillez en recr√©er une.")
    sys.exit()

# Initialisation du client OpenAI
client = openai.OpenAI(api_key=key)

if st.button("üé≤ G√©n√©rer une question"):
    with st.spinner("GPT pr√©pare une question adapt√©e..."):
        chapitre_choisi = chapitre_choisi or "Fonctions"

        prompt_data = {
            "instructions": f"""Tu es un professeur de math√©matiques. G√©n√©re une question de type QCM pour le niveau Premi√®re - Math√©matiques sp√©cifiques.

- Le th√®me est : {chapitre_choisi}
- R√©dige une question claire.
- Donne 4 propositions (A, B, C, D), dont une seule est correcte.
- M√©lange al√©atoirement l'ordre des propositions.
- Indique la lettre de la bonne r√©ponse.
- Donne une explication claire et p√©dagogique pour justifier la bonne r√©ponse, m√™me si l'√©l√®ve s‚Äôest tromp√©.

R√©ponds dans ce format JSON structur√© :""",
            "json_format": {
                "question": "...",
                "options": {
                    "A": "...",
                    "B": "...",
                    "C": "...",
                    "D": "..."
                },
                "correct_answer": "B",
                "explanation": "..."
            }
        }

        prompt = prompt_data["instructions"] + "\n\n" + json.dumps(prompt_data["json_format"], indent=2)

        try:
            response = client.chat.completions.create(
                model="gpt-3.5-turbo",
                messages=[{"role": "user", "content": prompt}],
                temperature=0.7
            )

            content = response.choices[0].message.content

            # Tente de parser le JSON g√©n√©r√©
            data = json.loads(content)

            st.markdown(f"### ‚ùì Question :\n{data['question']}")
            options = data["options"]

            user_answer = st.radio("Choisis ta r√©ponse :", list(options.keys()), format_func=lambda x: f"{x} : {options[x]}")

            if user_answer:
                if user_answer == data["correct_answer"]:
                    st.success("‚úÖ Bonne r√©ponse !")
                else:
                    st.error(f"‚ùå Mauvaise r√©ponse. La bonne r√©ponse √©tait {data['correct_answer']} : {options[data['correct_answer']]}")
                st.markdown(f"**Explication** : {data['explanation']}")

        except Exception as e:
            st.error(f"‚ùå Une erreur est survenue : {e}")
