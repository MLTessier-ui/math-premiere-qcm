# -*- coding: utf-8 -*-

import streamlit as st
import json
import openai

import sys

key = st.secrets["OPENAI_API_KEY"]

try:
    key.encode("ascii")
except UnicodeEncodeError:
    st.error("‚ùå La cl√© API contient un caract√®re accentu√© ou invisible. Veuillez en recr√©er une.")
    sys.exit()

# Initialisation du client OpenAI avec la cl√© depuis les secrets
client = openai.OpenAI(api_key=st.secrets["OPENAI_API_KEY"])

# Liste des chapitres du programme sp√©cifique de Premi√®re
chapitres = [
    "Fonctions",
    "Calcul litt√©ral",
    "Statistiques",
    "Probabilit√©s",
    "G√©om√©trie",
    "Nombres et calculs",
    "Grandeurs et mesures"
]

st.set_page_config(page_title="Chatbot QCM Maths", page_icon="üßÆ")
st.title("ü§ñ Chatbot QCM ‚Äì Maths Premi√®re (enseignement sp√©cifique)")
st.markdown("Choisis un chapitre pour g√©n√©rer une question de QCM adapt√©e au programme.")

# Choix de chapitre
chapitre_choisi = st.selectbox("üìò Chapitre :", chapitres)

if st.button("üé≤ G√©n√©rer une question"):
    with st.spinner("GPT pr√©pare une question adapt√©e..."):
        chapitre_choisi = chapitre_choisi or "Fonctions"

        # ‚úÖ D√©finir le prompt ici, juste avant l'appel √† l'API
        prompt = f"""
Tu es un professeur de math√©matiques. G√©n√©re une question de type QCM pour le niveau Premi√®re - Math√©matiques sp√©cifiques (anciennement appel√© "Maths expertes"). 

- Le th√®me est : [ins√©rer ici le chapitre choisi, par exemple "Fonctions", "Suites", etc.].
- R√©dige une question claire.
- Donne 4 propositions (A, B, C, D), dont une seule est correcte.
- M√©lange al√©atoirement l'ordre des propositions.
- Indique la lettre de la bonne r√©ponse.
- Donne une explication claire et p√©dagogique pour justifier la bonne r√©ponse, m√™me si l'√©l√®ve s‚Äôest tromp√©.

R√©ponds dans ce format JSON structur√© :

{
  "question": "...",
  "options": {
    "A": "...",
    "B": "...",
    "C": "...",
    "D": "..."
  },
  "correct_answer": "B",
  "explanation": "..."
}

"""

        try:
            response = client.chat.completions.create(
                model="gpt-3.5-turbo",
                messages=[{"role": "user", "content": prompt}],
                temperature=0.7
            )

            content = response.choices[0].message.content
            qcm_json = json.loads(content)

            st.subheader("‚ùì Question")
            st.write(qcm_json["question"])

            choix = st.radio("R√©ponses :", qcm_json["propositions"], key="choix")

            if st.button("‚úÖ Valider ma r√©ponse"):
                if choix.startswith(qcm_json["bonne_reponse"]):
                    st.success("Bonne r√©ponse ! üéâ")
                else:
                    st.error(f"Mauvaise r√©ponse. La bonne √©tait : {qcm_json['bonne_reponse']}")
                st.info("üß† Explication : " + qcm_json["explication"])

        except Exception as e:
            st.error("‚ùå Une erreur est survenue lors de la g√©n√©ration du QCM.")
            st.exception(e)
